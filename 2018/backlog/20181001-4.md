~~~
root@DataLX01:~/python/libgdf# pip install mmlspark -U
Looking in indexes: http://ftp.daumkakao.com/pypi/simple
Collecting mmlspark
  Could not find a version that satisfies the requirement mmlspark (from versions: )
No matching distribution found for mmlspark
root@DataLX01:~/python/libgdf# spark-shell --packages Azure:mmlspark:0.14
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
:: loading settings :: url = jar:file:/usr/local/lib/python3.6/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Azure#mmlspark added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-5e6f62ae-4bd1-470d-9208-1431619a5ceb;1.0
        confs: [default]
        found Azure#mmlspark;0.14 in spark-packages
        found io.spray#spray-json_2.11;1.3.2 in central
        found com.microsoft.cntk#cntk;2.4 in central
        found org.openpnp#opencv;3.2.0-1 in central
        found com.jcraft#jsch;0.1.54 in central
        found com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 in central
downloading http://dl.bintray.com/spark-packages/maven/Azure/mmlspark/0.14/mmlspark-0.14.jar ...
        [SUCCESSFUL ] Azure#mmlspark;0.14!mmlspark.jar (17652ms)
downloading https://repo1.maven.org/maven2/io/spray/spray-json_2.11/1.3.2/spray-json_2.11-1.3.2.jar ...
        [SUCCESSFUL ] io.spray#spray-json_2.11;1.3.2!spray-json_2.11.jar(bundle) (1351ms)
downloading https://repo1.maven.org/maven2/com/microsoft/cntk/cntk/2.4/cntk-2.4.jar ...
        [SUCCESSFUL ] com.microsoft.cntk#cntk;2.4!cntk.jar (432301ms)
downloading https://repo1.maven.org/maven2/org/openpnp/opencv/3.2.0-1/opencv-3.2.0-1.jar ...
        [SUCCESSFUL ] org.openpnp#opencv;3.2.0-1!opencv.jar(bundle) (415055ms)
downloading https://repo1.maven.org/maven2/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar ...
        [SUCCESSFUL ] com.jcraft#jsch;0.1.54!jsch.jar (802ms)
downloading https://repo1.maven.org/maven2/com/microsoft/ml/lightgbm/lightgbmlib/2.1.250/lightgbmlib-2.1.250.jar ...
        [SUCCESSFUL ] com.microsoft.ml.lightgbm#lightgbmlib;2.1.250!lightgbmlib.jar (7280ms)
:: resolution report :: resolve 30697ms :: artifacts dl 874447ms
        :: modules in use:
        Azure#mmlspark;0.14 from spark-packages in [default]
        com.jcraft#jsch;0.1.54 from central in [default]
        com.microsoft.cntk#cntk;2.4 from central in [default]
        com.microsoft.ml.lightgbm#lightgbmlib;2.1.250 from central in [default]
        io.spray#spray-json_2.11;1.3.2 from central in [default]
        org.openpnp#opencv;3.2.0-1 from central in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   6   |   6   |   6   |   0   ||   6   |   6   |
        ---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-5e6f62ae-4bd1-470d-9208-1431619a5ceb
        confs: [default]
        6 artifacts copied, 0 already retrieved (264807kB/291ms)
2018-10-01 16:09:54 WARN  Utils:66 - Your hostname, DataLX01 resolves to a loopback address: 127.0.0.1; using 192.168.1.51 instead (on interface bond0)
2018-10-01 16:09:54 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-10-01 16:09:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://DataLX01:4040
Spark context available as 'sc' (master = local[*], app id = local-1538377800538).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.3.2
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_181)
Type in expressions to have them evaluated.
Type :help for more information.

scala> 
~~~

~~~
scala> root@DataLX01:~/python/libgdf# pip install kaggle -U
Looking in indexes: http://ftp.daumkakao.com/pypi/simple
Collecting kaggle
  Downloading http://mirror.kakao.com/pypi/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)
    100% |████████████████████████████████| 61kB 1.4MB/s 
Requirement already satisfied, skipping upgrade: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)
Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)
Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.1.18)
Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.7.0)
Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)
Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.26.0)
Collecting python-slugify (from kaggle)
  Downloading http://mirror.kakao.com/pypi/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz
Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)
Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)
Requirement already satisfied, skipping upgrade: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.22)
Building wheels for collected packages: kaggle, python-slugify
  Running setup.py bdist_wheel for kaggle ... done
  Stored in directory: /root/.cache/pip/wheels/59/5f/ae/7d609590f1ff97853a5aefa3f365591e7ff3d7c5261129cd1a
  Running setup.py bdist_wheel for python-slugify ... done
  Stored in directory: /root/.cache/pip/wheels/de/9f/4e/249d2b146eddabe3094644692961ab25cd2533a29996eedc13
Successfully built kaggle python-slugify
Installing collected packages: python-slugify, kaggle
Successfully installed kaggle-1.4.7.1 python-slugify-1.2.6
root@DataLX01:~/python/libgdf# kaggle
~~~
